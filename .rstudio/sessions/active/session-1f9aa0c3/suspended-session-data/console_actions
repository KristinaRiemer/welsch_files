{
    "data" : [
        "2019-09-05 17:41:47 WARN   [read.output] : \n   read.output: no netCDF files of model output present for runid = \n   SA-Setaria WT-stomatal_slope.BB-0.159 in \n   /home/kristinariemer/biocro_darpa_results/out/SA-Setaria \n   WT-stomatal_slope.BB-0.159 for years 2004 : 2004 . Returning NA. \n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   No files found. Returning all NA. \n",
        "Warning in mean.default(out, na.rm = TRUE) :",
        "\n ",
        " argument is not numeric or logical: returning NA\n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   Reading the following files: \n   /home/kristinariemer/biocro_darpa_results/out/SA-median/2004.nc \n",
        "2019-09-05 17:41:47 INFO   [read.output] : Result summary:\n              Mean Median\nAbvGrndWood 0.463   0.53 \n",
        "2019-09-05 17:41:47 WARN   [read.output] : \n   read.output: no netCDF files of model output present for runid = \n   SA-Setaria WT-stomatal_slope.BB-0.841 in \n   /home/kristinariemer/biocro_darpa_results/out/SA-Setaria \n   WT-stomatal_slope.BB-0.841 for years 2004 : 2004 . Returning NA. \n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   No files found. Returning all NA. \n",
        "Warning in mean.default(out, na.rm = TRUE) :",
        "\n ",
        " argument is not numeric or logical: returning NA\n",
        "2019-09-05 17:41:47 INFO   [read.sa.output] : \n   reading sensitivity analysis output for model run at 15.866 50 84.134 \n   quantiles of trait stomatal_slope.BB \n",
        "2019-09-05 17:41:47 WARN   [read.output] : \n   read.output: no netCDF files of model output present for runid = \n   SA-Setaria WT-growth_respiration_coefficient-0.159 in \n   /home/kristinariemer/biocro_darpa_results/out/SA-Setaria \n   WT-growth_respiration_coefficient-0.159 for years 2004 : 2004 . \n   Returning NA. \n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   No files found. Returning all NA. \n",
        "Warning in mean.default(out, na.rm = TRUE) :",
        "\n ",
        " argument is not numeric or logical: returning NA\n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   Reading the following files: \n   /home/kristinariemer/biocro_darpa_results/out/SA-median/2004.nc \n",
        "2019-09-05 17:41:47 INFO   [read.output] : Result summary:\n              Mean Median\nAbvGrndWood 0.463   0.53 \n",
        "2019-09-05 17:41:47 WARN   [read.output] : \n   read.output: no netCDF files of model output present for runid = \n   SA-Setaria WT-growth_respiration_coefficient-0.841 in \n   /home/kristinariemer/biocro_darpa_results/out/SA-Setaria \n   WT-growth_respiration_coefficient-0.841 for years 2004 : 2004 . \n   Returning NA. \n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   No files found. Returning all NA. \n",
        "Warning in mean.default(out, na.rm = TRUE) :",
        "\n ",
        " argument is not numeric or logical: returning NA\n",
        "2019-09-05 17:41:47 INFO   [read.sa.output] : \n   reading sensitivity analysis output for model run at 15.866 50 84.134 \n   quantiles of trait growth_respiration_coefficient \n",
        "2019-09-05 17:41:47 WARN   [read.output] : \n   read.output: no netCDF files of model output present for runid = \n   SA-Setaria WT-extinction_coefficient_diffuse-0.159 in \n   /home/kristinariemer/biocro_darpa_results/out/SA-Setaria \n   WT-extinction_coefficient_diffuse-0.159 for years 2004 : 2004 . \n   Returning NA. \n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   No files found. Returning all NA. \n",
        "Warning in mean.default(out, na.rm = TRUE) :",
        "\n ",
        " argument is not numeric or logical: returning NA\n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   Reading the following files: \n   /home/kristinariemer/biocro_darpa_results/out/SA-median/2004.nc \n",
        "2019-09-05 17:41:47 INFO   [read.output] : Result summary:\n              Mean Median\nAbvGrndWood 0.463   0.53 \n",
        "2019-09-05 17:41:47 WARN   [read.output] : \n   read.output: no netCDF files of model output present for runid = \n   SA-Setaria WT-extinction_coefficient_diffuse-0.841 in \n   /home/kristinariemer/biocro_darpa_results/out/SA-Setaria \n   WT-extinction_coefficient_diffuse-0.841 for years 2004 : 2004 . \n   Returning NA. \n",
        "2019-09-05 17:41:47 INFO   [read.output] : \n   No files found. Returning all NA. \n",
        "Warning in mean.default(out, na.rm = TRUE) :",
        "\n ",
        " argument is not numeric or logical: returning NA\n",
        "2019-09-05 17:41:47 INFO   [read.sa.output] : \n   reading sensitivity analysis output for model run at 15.866 50 84.134 \n   quantiles of trait extinction_coefficient_diffuse \n",
        "2019-09-05 17:41:47 INFO   [PEcAn.uncertainty::read.ensemble.output] : \n   reading ensemble output from run id: ENS-00001-9000000000 \n",
        "2019-09-05 17:41:47 INFO   [PEcAn.utils::read.output] : \n   Reading the following files: \n   /home/kristinariemer/biocro_darpa_results/out/ENS-00001-9000000000/2004.nc \n",
        "2019-09-05 17:41:47 INFO   [PEcAn.utils::read.output] : Result summary:\n              Mean Median\nAbvGrndWood 0.463   0.53 \n",
        "> ",
        "",
        "> ",
        "# Run ensemble analysis on model output.",
        "> ",
        "if ('ensemble' %in% names(settings) & PEcAn.utils::status.check(\"ENSEMBLE\") == 0) {",
        "+ ",
        "  PEcAn.utils::status.start(\"ENSEMBLE\")",
        "+ ",
        "  runModule.run.ensemble.analysis(settings, TRUE)",
        "+ ",
        "  PEcAn.utils::status.end()",
        "+ ",
        "}",
        "[1] \"----- Variable: AbvGrndWood\"\n[1] \"----- Running ensemble analysis for site:  Donald Danforth Plant Science Center Growth Chamber 157\"\n[1] \"----- Done!\"\n[1] \" \"\n[1] \"-----------------------------------------------\"\n[1] \" \"\n[1] \" \"\n[1] \"------ Generating ensemble time-series plot ------\"\n[1] \"----- Variable: AbvGrndWood\"\n[1] \"----- Reading ensemble output ------\"\n[1] \"ENS-00001-9000000000\"\n",
        "2019-09-05 17:41:47 INFO   [PEcAn.utils::read.output] : \n   Reading the following files: \n   /home/kristinariemer/biocro_darpa_results/out/ENS-00001-9000000000/2004.nc \n",
        "2019-09-05 17:41:47 INFO   [PEcAn.utils::read.output] : Result summary:\n              Mean Median\nAbvGrndWood 0.463   0.53 \n",
        "> ",
        "",
        "> ",
        "# Run sensitivity analysis and variance decomposition on model output",
        "> ",
        "if ('sensitivity.analysis' %in% names(settings) & PEcAn.utils::status.check(\"SENSITIVITY\") == 0) {",
        "+ ",
        "  PEcAn.utils::status.start(\"SENSITIVITY\")",
        "+ ",
        "  runModule.run.sensitivity.analysis(settings)",
        "+ ",
        "  PEcAn.utils::status.end()",
        "+ ",
        "}",
        "debugging in: sensitivity.analysis(trait.samples = trait.samples[[pft$name]][traits], \n    sa.samples = sa.samples[[pft$name]][, traits, drop = FALSE], \n    sa.output = sensitivity.output[[pft$name]][, traits, drop = FALSE], \n    outdir = pft$outdir)\ndebug: {\n    traits <- names(trait.samples)\n    sa.splines <- sapply(traits, function(trait) sa.splinefun(sa.samples[[trait]], \n        sa.output[[trait]]))\n    spline.estimates <- lapply(traits, function(trait) spline.truncate(sa.splines[[trait]](trait.samples[[trait]])))\n",
        "    names(spline.estimates) <- traits\n    sensitivities <- sapply(traits, function(trait) get.sensitivity(trait.samples[[trait]], \n        sa.splines[[trait]]))\n    elasticities <- sapply(traits, function(trait) get.elasticity(sensitivities[[trait]], \n        trait.samples[[trait]], spline.estimates[[trait]]))\n    variances <- sapply(traits, function(trait) var(spline.estimates[[trait]]))\n    partial.variances <- variances/sum(variances)\n    coef.vars <- sapply(trait.samples, get.coef.var)\n    outlist <- list(sensitivity.output = list(sa.samples = sa.samples, \n",
        "        sa.splines = sa.splines), variance.decomposition.output = list(coef.vars = coef.vars, \n        elasticities = elasticities, sensitivities = sensitivities, \n        variances = variances, partial.variances = partial.variances))\n    return(outlist)\n}\n",
        "Browse[2]> ",
        "sa.samples",
        "          Vcmax c2n_leaf cuticular_cond      SLA leaf_respiration_rate_m2\n15.866 31.53793 17.02121       1827.726 37.25736                0.9876374\n50     42.37284 29.66239       4489.626 43.84643                1.8910358\n84.134 57.14740 48.04495      11021.264 48.90872                3.6591534\n       stomatal_slope.BB growth_respiration_coefficient\n15.866          2.623827                      0.2954298\n50              3.464502                      0.3506820\n84.134          4.594318                      0.4066617",
        "\n       extinction_coefficient_diffuse\n15.866                      0.2795031\n50                          0.4680147\n84.134                      0.7169049\n",
        "Browse[2]> ",
        "sa.samples",
        "          Vcmax c2n_leaf cuticular_cond      SLA leaf_respiration_rate_m2\n15.866 31.53793 17.02121       1827.726 37.25736                0.9876374\n50     42.37284 29.66239       4489.626 43.84643                1.8910358\n84.134 57.14740 48.04495      11021.264 48.90872                3.6591534\n       stomatal_slope.BB growth_respiration_coefficient\n15.866          2.623827                      0.2954298\n50              3.464502                      0.3506820\n84.134          4.594318                      0.4066617",
        "\n       extinction_coefficient_diffuse\n15.866                      0.2795031\n50                          0.4680147\n84.134                      0.7169049\n",
        "Browse[2]> ",
        "sensitivity.output",
        "Error: object 'sensitivity.output' not found\n",
        "Browse[2]> ",
        "sensitivity.output[[pft$name]]",
        "Error: object 'sensitivity.output' not found\n",
        "Browse[2]> ",
        "pft$names",
        "Error: object 'pft' not found\n",
        "Browse[2]> ",
        "Q",
        "\nRestarting R session...\n\n",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "PEcAn.visualization::plot.netcdf(\"biocro_darpa_results/out/ENS-00001-9000000000/2004.nc\", \"LAI\")",
        "Warning message:\n",
        "In readPNG(system.file(\"favicon.png\", package = \"PEcAn.visualization\")) :",
        "\n ",
        " libpng warning: iCCP: known incorrect sRGB profile\n",
        "> ",
        "",
        "\nRestarting R session...\n\n",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# Load required libraries",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "library(PEcAn.all)",
        "Loading required package: PEcAn.DB\n",
        "Loading required package: PEcAn.settings\n",
        "Loading required package: PEcAn.MA\n",
        "Loading required package: XML\n",
        "Loading required package: lattice\n",
        "Loading required package: MASS\n",
        "Loading required package: PEcAn.utils\n",
        "\nAttaching package: ‘PEcAn.utils’\n\n",
        "The following object is masked from ‘package:utils’:\n\n    download.file\n\n",
        "Loading required package: PEcAn.logger\n",
        "\nAttaching package: ‘PEcAn.logger’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    logger.debug, logger.error, logger.getLevel,\n    logger.info, logger.setLevel,\n    logger.setOutputFile, logger.setQuitOnSevere,\n    logger.setWidth, logger.severe, logger.warn\n\n",
        "Loading required package: PEcAn.uncertainty\n",
        "Loading required package: PEcAn.priors\n",
        "Loading required package: ggplot2\n",
        "Loading required package: ggmap\n",
        "Google Maps API Terms of Service: http://developers.google.com/maps/terms.\n",
        "Please cite ggmap if you use it: see citation('ggmap') for details.\n",
        "Loading required package: gridExtra\n",
        "\nAttaching package: ‘PEcAn.uncertainty’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    get.ensemble.samples, read.ensemble.output,\n    write.ensemble.configs\n\n",
        "Loading required package: PEcAn.data.atmosphere\n",
        "Loading required package: PEcAn.data.land\n",
        "Loading required package: datapack\n",
        "Loading required package: dataone\n",
        "Loading required package: redland\n",
        "Loading required package: sirt\n",
        "- sirt 3.1-80 (2019-01-04 12:08:59)\n",
        "Loading required package: sf\n",
        "Linking to GEOS 3.5.1, GDAL 2.1.2, PROJ 4.9.3\n",
        "Loading required package: PEcAn.data.remote\n",
        "Loading required package: PEcAn.assim.batch\n",
        "Loading required package: PEcAn.emulator\n",
        "Loading required package: mvtnorm\n",
        "Loading required package: mlegp\n",
        "Loading required package: MCMCpack\n",
        "Loading required package: coda\n",
        "##\n## Markov Chain Monte Carlo Package (MCMCpack)\n",
        "## Copyright (C) 2003-2019 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n",
        "##\n## Support provided by the U.S. National Science Foundation\n",
        "## (Grants SES-0350646 and SES-0350613)\n##\n",
        "Loading required package: PEcAn.benchmark\n",
        "Loading required package: PEcAn.remote\n",
        "Loading required package: PEcAn.workflow\n",
        "\nAttaching package: ‘PEcAn.workflow’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    do_conversions, run.write.configs,\n    runModule.run.write.configs\n\n",
        "> ",
        "debugonce(PEcAn.DB::get.trait.data.pft)",
        "> ",
        "library(PEcAn.utils)",
        "> ",
        "library(RCurl)",
        "Loading required package: bitops\n",
        "> ",
        "# make sure always to call status.end",
        "> ",
        "options(warn=1)",
        "> ",
        "options(error=quote({",
        "+ ",
        "  PEcAn.utils::status.end(\"ERROR\")",
        "+ ",
        "  PEcAn.remote::kill.tunnel(settings)",
        "+ ",
        "  if (!interactive()) {",
        "+ ",
        "    q(status = 1)",
        "+ ",
        "  }",
        "+ ",
        "}))",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# PEcAn Workflow",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# Open and read in settings file for PEcAn run.",
        "> ",
        "args <- commandArgs(trailingOnly = TRUE)",
        "> ",
        "if (is.na(args[1])){",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(\"pecan.xml\") ",
        "+ ",
        "} else {",
        "+ ",
        "  settings.file <- args[1]",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(settings.file)",
        "+ ",
        "}",
        "2019-09-09 18:48:51 SEVERE [#2: PEcAn.settings::read.settings] : \n   Could not find a pecan.xml file \n",
        "Error in PEcAn.remote::kill.tunnel(settings) : \n  object 'settings' not found\n",
        "Error during wrapup: ",
        "object 'settings' not found\n",
        "> ",
        "# Check for additional modules that will require adding settings",
        "> ",
        "if(\"benchmarking\" %in% names(settings)){",
        "+ ",
        "  library(PEcAn.benchmark)",
        "+ ",
        "  settings <- papply(settings, read_settings_BRR)",
        "+ ",
        "}",
        "Error in \"benchmarking\" %in% names(settings) : \n  object 'settings' not found\n",
        "Error during wrapup: ",
        "object 'settings' not found\n",
        "> ",
        "if(\"sitegroup\" %in% names(settings)){",
        "+ ",
        "  if(is.null(settings$sitegroup$nSite)){",
        "+ ",
        "    settings <- PEcAn.settings::createSitegroupMultiSettings(settings, ",
        "+ ",
        "                                                             sitegroupId = settings$sitegroup$id)",
        "+ ",
        "  } else {",
        "+ ",
        "    settings <- PEcAn.settings::createSitegroupMultiSettings(settings, ",
        "+ ",
        "                                                             sitegroupId = settings$sitegroup$id,",
        "+ ",
        "                                                             nSite = settings$sitegroup$nSite)",
        "+ ",
        "  }",
        "+ ",
        "  settings$sitegroup <- NULL ## zero out so don't expand a second time if re-reading",
        "+ ",
        "}",
        "Error in \"sitegroup\" %in% names(settings) : object 'settings' not found\n",
        "Error during wrapup: ",
        "object 'settings' not found\n",
        "\nRestarting R session...\n\n",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# Load required libraries",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "library(PEcAn.all)",
        "Loading required package: PEcAn.DB\n",
        "Loading required package: PEcAn.settings\n",
        "Loading required package: PEcAn.MA\n",
        "Loading required package: XML\n",
        "Loading required package: lattice\n",
        "Loading required package: MASS\n",
        "Loading required package: PEcAn.utils\n",
        "\nAttaching package: ‘PEcAn.utils’\n\n",
        "The following object is masked from ‘package:utils’:\n\n    download.file\n\n",
        "Loading required package: PEcAn.logger\n",
        "\nAttaching package: ‘PEcAn.logger’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    logger.debug, logger.error, logger.getLevel,\n    logger.info, logger.setLevel,\n    logger.setOutputFile, logger.setQuitOnSevere,\n    logger.setWidth, logger.severe, logger.warn\n\n",
        "Loading required package: PEcAn.uncertainty\n",
        "Loading required package: PEcAn.priors\n",
        "Loading required package: ggplot2\n",
        "Loading required package: ggmap\n",
        "Google Maps API Terms of Service: http://developers.google.com/maps/terms.\n",
        "Please cite ggmap if you use it: see citation('ggmap') for details.\n",
        "Loading required package: gridExtra\n",
        "\nAttaching package: ‘PEcAn.uncertainty’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    get.ensemble.samples, read.ensemble.output,\n    write.ensemble.configs\n\n",
        "Loading required package: PEcAn.data.atmosphere\n",
        "Loading required package: PEcAn.data.land\n",
        "Loading required package: datapack\n",
        "Loading required package: dataone\n",
        "Loading required package: redland\n",
        "Loading required package: sirt\n",
        "- sirt 3.1-80 (2019-01-04 12:08:59)\n",
        "Loading required package: sf\n",
        "Linking to GEOS 3.5.1, GDAL 2.1.2, PROJ 4.9.3\n",
        "Loading required package: PEcAn.data.remote\n",
        "Loading required package: PEcAn.assim.batch\n",
        "Loading required package: PEcAn.emulator\n",
        "Loading required package: mvtnorm\n",
        "Loading required package: mlegp\n",
        "Loading required package: MCMCpack\n",
        "Loading required package: coda\n",
        "##\n## Markov Chain Monte Carlo Package (MCMCpack)\n",
        "## Copyright (C) 2003-2019 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n",
        "##\n## Support provided by the U.S. National Science Foundation\n",
        "## (Grants SES-0350646 and SES-0350613)\n##\n",
        "Loading required package: PEcAn.benchmark\n",
        "Loading required package: PEcAn.remote\n",
        "Loading required package: PEcAn.workflow\n",
        "\nAttaching package: ‘PEcAn.workflow’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    do_conversions, run.write.configs,\n    runModule.run.write.configs\n\n",
        "> ",
        "debugonce(PEcAn.DB::get.trait.data.pft)",
        "> ",
        "library(PEcAn.utils)",
        "> ",
        "library(RCurl)",
        "Loading required package: bitops\n",
        "> ",
        "# make sure always to call status.end",
        "> ",
        "options(warn=1)",
        "> ",
        "options(error=quote({",
        "+ ",
        "  PEcAn.utils::status.end(\"ERROR\")",
        "+ ",
        "  PEcAn.remote::kill.tunnel(settings)",
        "+ ",
        "  if (!interactive()) {",
        "+ ",
        "    q(status = 1)",
        "+ ",
        "  }",
        "+ ",
        "}))",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# PEcAn Workflow",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# Open and read in settings file for PEcAn run.",
        "> ",
        "args <- commandArgs(trailingOnly = TRUE)",
        "> ",
        "if (is.na(args[1])){",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(\"biocro_darpa_files/pecan.biocro.darpa.xml\") ",
        "+ ",
        "} else {",
        "+ ",
        "  settings.file <- args[1]",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(settings.file)",
        "+ ",
        "}",
        "2019-09-09 18:49:21 INFO   [#2: PEcAn.settings::read.settings] : \n   Loading inpufile= biocro_darpa_files/pecan.biocro.darpa.xml \n",
        "> ",
        "# Check for additional modules that will require adding settings",
        "> ",
        "if(\"benchmarking\" %in% names(settings)){",
        "+ ",
        "  library(PEcAn.benchmark)",
        "+ ",
        "  settings <- papply(settings, read_settings_BRR)",
        "+ ",
        "}",
        "> ",
        "if(\"sitegroup\" %in% names(settings)){",
        "+ ",
        "  if(is.null(settings$sitegroup$nSite)){",
        "+ ",
        "    settings <- PEcAn.settings::createSitegroupMultiSettings(settings, ",
        "+ ",
        "                                                             sitegroupId = settings$sitegroup$id)",
        "+ ",
        "  } else {",
        "+ ",
        "    settings <- PEcAn.settings::createSitegroupMultiSettings(settings, ",
        "+ ",
        "                                                             sitegroupId = settings$sitegroup$id,",
        "+ ",
        "                                                             nSite = settings$sitegroup$nSite)",
        "+ ",
        "  }",
        "+ ",
        "  settings$sitegroup <- NULL ## zero out so don't expand a second time if re-reading",
        "+ ",
        "}",
        "> ",
        "# Update/fix/check settings. Will only run the first time it's called, unless force=TRUE",
        "> ",
        "settings <- PEcAn.settings::prepare.settings(settings, force = FALSE)",
        "2019-09-09 18:49:23 INFO   [fix.deprecated.settings] : \n   Fixing deprecated settings... \n",
        "2019-09-09 18:49:23 INFO   [fix.deprecated.settings] : \n   settings$run$host is deprecated. uwe settings$host instead \n",
        "2019-09-09 18:49:23 INFO   [update.settings] : \n   Fixing deprecated settings... \n",
        "2019-09-09 18:49:23 INFO   [check.settings] : Checking settings... \n",
        "2019-09-09 18:49:24 INFO   [check.database] : \n   Successfully connected to database : PostgreSQL bety bety postgres bety \n   FALSE \n",
        "2019-09-09 18:49:24 WARN   [check.database.settings] : \n   Will not write runs/configurations to database. \n",
        "2019-09-09 18:49:24 WARN   [check.bety.version] : \n   Last migration 20181129000515 is more recent than expected \n   20141009160121. This could result in PEcAn not working as expected. \n",
        "2019-09-09 18:49:24 INFO   [check.ensemble.settings] : \n   Setting ensemble size to 1. \n",
        "2019-09-09 18:49:24 INFO   [check.ensemble.settings] : \n   No start date passed to ensemble - using the run date ( 2004 ). \n",
        "2019-09-09 18:49:24 INFO   [check.ensemble.settings] : \n   No end date passed to ensemble - using the run date ( 2004 ). \n",
        "2019-09-09 18:49:24 INFO   [check.ensemble.settings] : \n   We are updating the ensemble tag inside the xml file. \n",
        "2019-09-09 18:49:24 INFO   [fn] : \n   Setting site name to Donald Danforth Plant Science Center Growth Chamber \n   157 \n",
        "2019-09-09 18:49:24 INFO   [fn] : \n   Setting site lat to 38.674593 \n",
        "2019-09-09 18:49:24 INFO   [fn] : \n   Setting site lon to -90.397189 \n",
        "2019-09-09 18:49:24 WARN   [check.model.settings] : \n   Model type BIOCRO not in database \n",
        "2019-09-09 18:49:24 INFO   [check.model.settings] : \n   Setting model id to -1 \n",
        "2019-09-09 18:49:24 INFO   [check.model.settings] : \n   Option to delete raw model output not set or not logical. Will keep all \n   model output. \n",
        "2019-09-09 18:49:24 WARN   [check.model.settings] : \n   No model binary sepcified in database for model BIOCRO \n",
        "2019-09-09 18:49:24 WARN   [check.settings] : \n   settings$database$dbfiles pathname biocro_darpa_results/dbfiles is \n   invalid \n  \n   placing it in the home directory /home/kristinariemer \n",
        "2019-09-09 18:49:24 INFO   [fn] : \n   Missing optional input : soil \n",
        "2019-09-09 18:49:24 WARN   [PEcAn.DB::dbfile.id] : \n   no id found for \n   /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 in \n   database \n",
        "2019-09-09 18:49:24 INFO   [fn] : \n   path /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "2019-09-09 18:49:24 INFO   [fn] : \n   path /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "2019-09-09 18:49:24 INFO   [check.workflow.settings] : \n   output folder = /home/kristinariemer/biocro_darpa_results \n",
        "2019-09-09 18:49:25 INFO   [check.settings] : \n   Storing pft Setaria WT in \n   /home/kristinariemer/biocro_darpa_results/pft/Setaria WT \n",
        "> ",
        "# Write pecan.CHECKED.xml",
        "> ",
        "PEcAn.settings::write.settings(settings, outputfile = \"pecan.CHECKED.xml\")",
        "2019-09-09 18:49:25 WARN   [PEcAn.settings::write.settings] : \n   File already exists [ \n   /home/kristinariemer/biocro_darpa_results/pecan.CHECKED.xml ] file will \n   be overwritten \n",
        "[1] \"/home/kristinariemer/biocro_darpa_results/pecan.CHECKED.xml\"\n",
        "> ",
        "# start from scratch if no continue is passed in",
        "> ",
        "statusFile <- file.path(settings$outdir, \"STATUS\")",
        "> ",
        "if (length(which(commandArgs() == \"--continue\")) == 0 && file.exists(statusFile)) {",
        "+ ",
        "  file.remove(statusFile)",
        "+ ",
        "}",
        "[1] TRUE\n",
        "> ",
        "# Do conversions",
        "> ",
        "settings <- PEcAn.workflow::do_conversions(settings)",
        "2019-09-09 18:49:25 DEBUG  [PEcAn.workflow::do_conversions] : \n   do.conversion outdir /home/kristinariemer/biocro_darpa_results/dbfiles \n",
        "2019-09-09 18:49:25 INFO   [PEcAn.workflow::do_conversions] : PROCESSING:  met \n",
        "2019-09-09 18:49:25 INFO   [PEcAn.workflow::do_conversions] : \n   calling met.process: \n   /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "2019-09-09 18:49:25 WARN   [PEcAn.data.atmosphere::met.process] : \n   met.process only has a path provided, assuming path is model driver and \n   skipping processing \n",
        "2019-09-09 18:49:25 DEBUG  [PEcAn.workflow::do_conversions] : \n   updated met path: \n   /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "> ",
        "# Query the trait database for data and priors",
        "> ",
        "if (PEcAn.utils::status.check(\"TRAIT\") == 0){",
        "+ ",
        "  PEcAn.utils::status.start(\"TRAIT\")",
        "+ ",
        "  settings <- PEcAn.workflow::runModule.get.trait.data(settings)",
        "+ ",
        "  PEcAn.settings::write.settings(settings, outputfile='pecan.TRAIT.xml')",
        "+ ",
        "  PEcAn.utils::status.end()",
        "+ ",
        "} else if (file.exists(file.path(settings$outdir, 'pecan.TRAIT.xml'))) {",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(file.path(settings$outdir, 'pecan.TRAIT.xml'))",
        "+ ",
        "}",
        "2019-09-09 18:49:26 DEBUG  [PEcAn.DB::get.trait.data] : \n   `trait.names` is NULL, so retrieving all traits that have at least one \n   prior for these PFTs. \n",
        "debugging in: FUN(X[[i]], ...)\ndebug: {\n    if (!file.exists(pft$outdir) && !dir.create(pft$outdir, recursive = TRUE)) {\n        PEcAn.logger::logger.error(paste0(\"Couldn't create PFT output directory: \", \n            pft$outdir))\n    }\n    old.files <- list.files(path = pft$outdir, full.names = TRUE, \n        include.dirs = FALSE)\n    file.remove(old.files)\n    pftres <- query_pfts(dbcon, pft[[\"name\"]], modeltype)\n    pfttype <- pftres[[\"pft_type\"]]\n    pftid <- pftres[[\"id\"]]\n    if (nrow(pftres) > 1) {\n        PEcAn.logger::logger.severe(\"Multiple PFTs named\", pft[[\"name\"]], \n",
        "            \"found,\", \"with ids\", PEcAn.utils::vecpaste(pftres[[\"id\"]]), \n            \".\", \"Specify modeltype to fix this.\")\n    }\n    if (nrow(pftres) == 0) {\n        PEcAn.logger::logger.severe(\"Could not find pft\", pft[[\"name\"]])\n        return(NA)\n    }\n    if (pfttype == \"plant\") {\n        pft_member_filename = \"species.csv\"\n        pft_members <- PEcAn.DB::query.pft_species(pft$name, \n            modeltype, dbcon)\n    }\n    else if (pfttype == \"cultivar\") {\n        pft_member_filename = \"cultivars.csv\"\n",
        "        pft_members <- PEcAn.DB::query.pft_cultivars(pft$name, \n            modeltype, dbcon)\n    }\n    else {\n        PEcAn.logger::logger.severe(\"Unknown pft type! Expected 'plant' or 'cultivar', got\", \n            pfttype)\n    }\n    pft_members <- pft_members %>% dplyr::mutate_if(is.character, \n        ~dplyr::na_if(., \"\"))\n    prior.distns <- PEcAn.DB::query.priors(pft = pftid, trstr = PEcAn.utils::vecpaste(trait.names), \n        con = dbcon)\n    prior.distns <- prior.distns[which(!rownames(prior.distns) %in% \n",
        "        names(pft$constants)), ]\n    traits <- rownames(prior.distns)\n    trait.data.check <- PEcAn.DB::query.traits(ids = pft_members$id, \n        priors = traits, con = dbcon, update.check.only = TRUE, \n        ids_are_cultivars = (pfttype == \"cultivar\"))\n    traits <- names(trait.data.check)\n    if (!is.logical(forceupdate)) {\n        forceupdate <- FALSE\n    }\n    if (!forceupdate) {\n        if (is.null(pft$posteriorid)) {\n            recent_posterior <- dplyr::tbl(dbcon, \"posteriors\") %>% \n                dplyr::filter(pft_id == !!pftid) %>% dplyr::collect()\n",
        "            if (length(recent_posterior) > 0) {\n                pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% \n                  dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n                  head(1) %>% dplyr::pull(id)\n            }\n            else {\n                PEcAn.logger::logger.info(\"No previous posterior found. Forcing update\")\n            }\n        }\n        if (!is.null(pft$posteriorid)) {\n            files <- dbfile.check(type = \"Posterior\", container.id = pft$posteriorid, \n",
        "                con = dbcon, return.all = TRUE)\n            need_files <- c(trait_data = \"trait.data.Rdata\", \n                priors = \"prior.distns.Rdata\", pft_membership = pft_member_filename)\n            ids <- match(need_files, files$file_name)\n            names(ids) <- names(need_files)\n            if (any(is.na(ids))) {\n                missing_files <- need_files[is.na(ids)]\n                PEcAn.logger::logger.info(paste0(\"Forcing meta-analysis update because \", \n                  \"the following files are missing from the posterior: \", \n",
        "                  paste0(shQuote(missing_files), collapse = \", \")))\n                PEcAn.logger::logger.debug(\"\\n `dbfile.check` returned the following output:\\n\", \n                  PEcAn.logger::print2string(files), wrap = FALSE)\n            }\n            else {\n                PEcAn.logger::logger.debug(\"All posterior files are present. Performing additional checks \", \n                  \"to determine if meta-analysis needs to be updated.\")\n                need_paths <- file.path(files$file_path[ids], \n                  need_files)\n",
        "                names(need_paths) <- names(need_files)\n                files_exist <- file.exists(need_paths)\n                foundallfiles <- all(files_exist)\n                if (!foundallfiles) {\n                  PEcAn.logger::logger.warn(\"The following files are in database but not found on disk: \", \n                    paste(shQuote(need_files[!files_exist]), \n                      collapse = \", \"), \". \", \"Re-running meta-analysis.\")\n                }\n                else {\n                  PEcAn.logger::logger.debug(\"Checking if PFT membership has changed.\")\n",
        "                  existing_membership <- utils::read.csv(need_paths[[\"pft_membership\"]], \n                    colClasses = c(\"double\", \"character\", \"character\", \n                      \"character\"), stringsAsFactors = FALSE, \n                    na.strings = \"\")\n                  diff_membership <- symmetric_setdiff(existing_membership, \n                    pft_members, xname = \"existing\", yname = \"current\")\n                  if (nrow(diff_membership) > 0) {\n                    PEcAn.logger::logger.error(\"\\n PFT membership has changed. \\n\", \n",
        "                      \"Difference is:\\n\", PEcAn.logger::print2string(diff_membership), \n                      wrap = FALSE)\n                    foundallfiles <- FALSE\n                  }\n                  PEcAn.logger::logger.debug(\"Checking if priors have changed\")\n                  existing_prior <- PEcAn.utils::load_local(need_paths[[\"priors\"]])[[\"prior.distns\"]]\n                  diff_prior <- symmetric_setdiff(dplyr::as_tibble(prior.distns, \n                    rownames = \"trait\"), dplyr::as_tibble(existing_prior, \n",
        "                    rownames = \"trait\"))\n                  if (nrow(diff_prior) > 0) {\n                    PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                      \"Difference is:\\n\", PEcAn.logger::print2string(diff_prior), \n                      wrap = FALSE)\n                    foundallfiles <- FALSE\n                  }\n                  PEcAn.logger::logger.debug(\"Checking if trait data have changed\")\n                  existing_trait_data <- PEcAn.utils::load_local(need_paths[[\"trait_data\"]])[[\"trait.data\"]]\n",
        "                  if (length(trait.data.check) != length(existing_trait_data)) {\n                    PEcAn.logger::logger.warn(\"Lengths of new and existing `trait.data` differ. \", \n                      \"Re-running meta-analysis.\")\n                    foundallfiles <- FALSE\n                  }\n                  else if (length(trait.data.check) == 0) {\n                    PEcAn.logger::logger.warn(\"New and existing trait data are both empty. Skipping this check.\")\n                  }\n                  else {\n",
        "                    current_traits <- dplyr::bind_rows(trait.data.check, \n                      .id = \"trait\") %>% dplyr::select(-mean, \n                      -stat)\n                    existing_traits <- dplyr::bind_rows(existing_trait_data, \n                      .id = \"trait\") %>% dplyr::select(-mean, \n                      -stat)\n                    diff_traits <- symmetric_setdiff(current_traits, \n                      existing_traits)\n                    if (nrow(diff_traits) > 0) {\n                      diff_summary <- diff_traits %>% dplyr::count(source, \n",
        "                        trait)\n                      PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                        \"Here are the number of differing trait records by trait:\\n\", \n                        PEcAn.logger::print2string(diff_summary), \n                        wrap = FALSE)\n                      foundallfiles <- FALSE\n                    }\n                  }\n                }\n                if (foundallfiles) {\n                  PEcAn.logger::logger.info(\"Reusing existing files from posterior\", \n",
        "                    pft$posteriorid, \"for PFT\", shQuote(pft$name))\n                  for (id in seq_len(nrow(files))) {\n                    file.copy(from = file.path(files[[id, \"file_path\"]], \n                      files[[id, \"file_name\"]]), to = file.path(pft$outdir, \n                      files[[id, \"file_name\"]]))\n                  }\n                  done <- TRUE\n                  if (length(list.files(pft$outdir, \"post.distns.Rdata\")) == \n                    0) {\n                    all.files <- list.files(pft$outdir)\n",
        "                    post.distn.file <- all.files[grep(\"post\\\\.distns\\\\..*\\\\.Rdata\", \n                      all.files)]\n                    if (length(post.distn.file) > 1) \n                      PEcAn.logger::logger.severe(\"get.trait.data.pft() doesn't know how to \", \n                        \"handle multiple `post.distns.*.Rdata` files.\", \n                        \"Found the following files: \", paste(shQuote(post.distn.file), \n                          collapse = \", \"))\n                    else if (length(post.distn.file) == 1) {\n",
        "                      link_input <- file.path(pft[[\"outdir\"]], \n                        post.distn.file)\n                      link_target <- file.path(pft[[\"outdir\"]], \n                        \"post.distns.Rdata\")\n                      PEcAn.logger::logger.debug(\"Found exactly one posterior distribution file: \", \n                        shQuote(link_input), \". Symlinking it to PFT output directory: \", \n                        shQuote(link_target))\n                      file.symlink(from = link_input, to = link_target)\n",
        "                    }\n                    else {\n                      PEcAn.logger::logger.error(\"No previous posterior distribution file found. \", \n                        \"Most likely, trait data were retrieved, but meta-analysis \", \n                        \"was not run. Meta-analysis will be run.\")\n                      done <- FALSE\n                    }\n                  }\n                  if (done) \n                    return(pft)\n                }\n            }\n        }\n    }\n    trait.data <- query.traits(pft_members$id, traits, con = dbcon, \n",
        "        update.check.only = FALSE, ids_are_cultivars = (pfttype == \n            \"cultivar\"))\n    traits <- names(trait.data)\n    if (length(trait.data) > 0) {\n        trait_counts <- trait.data %>% dplyr::bind_rows(.id = \"trait\") %>% \n            dplyr::count(trait)\n        PEcAn.logger::logger.info(\"\\n Number of observations per trait for PFT \", \n            shQuote(pft[[\"name\"]]), \":\\n\", PEcAn.logger::print2string(trait_counts, \n                n = Inf), wrap = FALSE)\n    }\n    else {\n        PEcAn.logger::logger.warn(\"None of the requested traits were found for PFT \", \n",
        "            format(pft_members[[\"id\"]], scientific = FALSE))\n    }\n    old.files <- list.files(path = pft$outdir)\n    now <- format(x = Sys.time(), format = \"%Y-%m-%d %H:%M:%S\")\n    db.query(paste0(\"INSERT INTO posteriors (pft_id, created_at, updated_at) \", \n        \"VALUES (\", pftid, \", '\", now, \"', '\", now, \"')\"), con = dbcon)\n    pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% dplyr::filter(pft_id == \n        !!pftid, created_at == !!now) %>% dplyr::pull(id)\n    pathname <- file.path(dbfiles, \"posterior\", pft$posteriorid)\n",
        "    dir.create(pathname, showWarnings = FALSE, recursive = TRUE)\n    utils::write.csv(pft_members, file.path(pft$outdir, pft_member_filename), \n        row.names = FALSE)\n    save(prior.distns, file = file.path(pft$outdir, \"prior.distns.Rdata\"))\n    utils::write.csv(prior.distns, file.path(pft$outdir, \"prior.distns.csv\"), \n        row.names = TRUE)\n    PEcAn.logger::logger.info(\"\\n Summary of prior distributions for PFT \", \n        shQuote(pft$name), \":\\n\", PEcAn.logger::print2string(prior.distns), \n        wrap = FALSE)\n",
        "    trait.data.file <- file.path(pft$outdir, \"trait.data.Rdata\")\n    save(trait.data, file = trait.data.file)\n    utils::write.csv(dplyr::bind_rows(trait.data), file.path(pft$outdir, \n        \"trait.data.csv\"), row.names = FALSE)\n    store_files_all <- list.files(path = pft[[\"outdir\"]])\n    store_files <- setdiff(store_files_all, old.files)\n    PEcAn.logger::logger.debug(\"The following posterior files found in PFT outdir \", \n        \"(\", shQuote(pft[[\"outdir\"]]), \") will be registered in BETY \", \n        \"under posterior ID \", format(pft[[\"posteriorid\"]], scientific = FALSE), \n",
        "        \": \", paste(shQuote(store_files), collapse = \", \"), \". \", \n        \"The following files (if any) will not be registered because they already existed: \", \n        paste(shQuote(intersect(store_files, old.files)), collapse = \", \"), \n        wrap = FALSE)\n    for (file in store_files) {\n        filename <- file.path(pathname, file)\n        file.copy(file.path(pft$outdir, file), filename)\n        dbfile.insert(in.path = pathname, in.prefix = file, type = \"Posterior\", \n            id = pft[[\"posteriorid\"]], con = dbcon)\n",
        "    }\n    return(pft)\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (!file.exists(pft$outdir) && !dir.create(pft$outdir, recursive = TRUE)) {\n    PEcAn.logger::logger.error(paste0(\"Couldn't create PFT output directory: \", \n        pft$outdir))\n}\n",
        "Browse[2]> ",
        "",
        "debug: old.files <- list.files(path = pft$outdir, full.names = TRUE, \n    include.dirs = FALSE)\n",
        "Browse[2]> ",
        "",
        "debug: file.remove(old.files)\n",
        "Browse[2]> ",
        "",
        "debug: pftres <- query_pfts(dbcon, pft[[\"name\"]], modeltype)\n",
        "Browse[2]> ",
        "",
        "debug: pfttype <- pftres[[\"pft_type\"]]\n",
        "Browse[2]> ",
        "",
        "debug: pftid <- pftres[[\"id\"]]\n",
        "Browse[2]> ",
        "",
        "debug: if (nrow(pftres) > 1) {\n    PEcAn.logger::logger.severe(\"Multiple PFTs named\", pft[[\"name\"]], \n        \"found,\", \"with ids\", PEcAn.utils::vecpaste(pftres[[\"id\"]]), \n        \".\", \"Specify modeltype to fix this.\")\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (nrow(pftres) == 0) {\n    PEcAn.logger::logger.severe(\"Could not find pft\", pft[[\"name\"]])\n    return(NA)\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (pfttype == \"plant\") {\n    pft_member_filename = \"species.csv\"\n    pft_members <- PEcAn.DB::query.pft_species(pft$name, modeltype, \n        dbcon)\n} else if (pfttype == \"cultivar\") {\n    pft_member_filename = \"cultivars.csv\"\n    pft_members <- PEcAn.DB::query.pft_cultivars(pft$name, modeltype, \n        dbcon)\n} else {\n    PEcAn.logger::logger.severe(\"Unknown pft type! Expected 'plant' or 'cultivar', got\", \n        pfttype)\n}\n",
        "Browse[2]> ",
        "",
        "debug: pft_member_filename = \"species.csv\"\n",
        "Browse[2]> ",
        "",
        "debug: pft_members <- PEcAn.DB::query.pft_species(pft$name, modeltype, \n    dbcon)\n",
        "Browse[2]> ",
        "",
        "debug: pft_members <- pft_members %>% dplyr::mutate_if(is.character, \n    ~dplyr::na_if(., \"\"))\n",
        "Browse[2]> ",
        "",
        "debug: prior.distns <- PEcAn.DB::query.priors(pft = pftid, trstr = PEcAn.utils::vecpaste(trait.names), \n    con = dbcon)\n",
        "Browse[2]> ",
        "",
        "debug: prior.distns <- prior.distns[which(!rownames(prior.distns) %in% \n    names(pft$constants)), ]\n",
        "Browse[2]> ",
        "",
        "debug: traits <- rownames(prior.distns)\n",
        "Browse[2]> ",
        "",
        "debug: trait.data.check <- PEcAn.DB::query.traits(ids = pft_members$id, \n    priors = traits, con = dbcon, update.check.only = TRUE, ids_are_cultivars = (pfttype == \n        \"cultivar\"))\n",
        "Browse[2]> ",
        "",
        "debug: traits <- names(trait.data.check)\n",
        "Browse[2]> ",
        "",
        "debug: if (!is.logical(forceupdate)) {\n    forceupdate <- FALSE\n}\n",
        "Browse[2]> ",
        "",
        "debug: forceupdate <- FALSE\n",
        "Browse[2]> ",
        "",
        "debug: if (!forceupdate) {\n    if (is.null(pft$posteriorid)) {\n        recent_posterior <- dplyr::tbl(dbcon, \"posteriors\") %>% \n            dplyr::filter(pft_id == !!pftid) %>% dplyr::collect()\n        if (length(recent_posterior) > 0) {\n            pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% \n                dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n                head(1) %>% dplyr::pull(id)\n        }\n        else {\n            PEcAn.logger::logger.info(\"No previous posterior found. Forcing update\")\n",
        "        }\n    }\n    if (!is.null(pft$posteriorid)) {\n        files <- dbfile.check(type = \"Posterior\", container.id = pft$posteriorid, \n            con = dbcon, return.all = TRUE)\n        need_files <- c(trait_data = \"trait.data.Rdata\", priors = \"prior.distns.Rdata\", \n            pft_membership = pft_member_filename)\n        ids <- match(need_files, files$file_name)\n        names(ids) <- names(need_files)\n        if (any(is.na(ids))) {\n            missing_files <- need_files[is.na(ids)]\n            PEcAn.logger::logger.info(paste0(\"Forcing meta-analysis update because \", \n",
        "                \"the following files are missing from the posterior: \", \n                paste0(shQuote(missing_files), collapse = \", \")))\n            PEcAn.logger::logger.debug(\"\\n `dbfile.check` returned the following output:\\n\", \n                PEcAn.logger::print2string(files), wrap = FALSE)\n        }\n        else {\n            PEcAn.logger::logger.debug(\"All posterior files are present. Performing additional checks \", \n                \"to determine if meta-analysis needs to be updated.\")\n            need_paths <- file.path(files$file_path[ids], need_files)\n",
        "            names(need_paths) <- names(need_files)\n            files_exist <- file.exists(need_paths)\n            foundallfiles <- all(files_exist)\n            if (!foundallfiles) {\n                PEcAn.logger::logger.warn(\"The following files are in database but not found on disk: \", \n                  paste(shQuote(need_files[!files_exist]), collapse = \", \"), \n                  \". \", \"Re-running meta-analysis.\")\n            }\n            else {\n                PEcAn.logger::logger.debug(\"Checking if PFT membership has changed.\")\n",
        "                existing_membership <- utils::read.csv(need_paths[[\"pft_membership\"]], \n                  colClasses = c(\"double\", \"character\", \"character\", \n                    \"character\"), stringsAsFactors = FALSE, na.strings = \"\")\n                diff_membership <- symmetric_setdiff(existing_membership, \n                  pft_members, xname = \"existing\", yname = \"current\")\n                if (nrow(diff_membership) > 0) {\n                  PEcAn.logger::logger.error(\"\\n PFT membership has changed. \\n\", \n",
        "                    \"Difference is:\\n\", PEcAn.logger::print2string(diff_membership), \n                    wrap = FALSE)\n                  foundallfiles <- FALSE\n                }\n                PEcAn.logger::logger.debug(\"Checking if priors have changed\")\n                existing_prior <- PEcAn.utils::load_local(need_paths[[\"priors\"]])[[\"prior.distns\"]]\n                diff_prior <- symmetric_setdiff(dplyr::as_tibble(prior.distns, \n                  rownames = \"trait\"), dplyr::as_tibble(existing_prior, \n                  rownames = \"trait\"))\n",
        "                if (nrow(diff_prior) > 0) {\n                  PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                    \"Difference is:\\n\", PEcAn.logger::print2string(diff_prior), \n                    wrap = FALSE)\n                  foundallfiles <- FALSE\n                }\n                PEcAn.logger::logger.debug(\"Checking if trait data have changed\")\n                existing_trait_data <- PEcAn.utils::load_local(need_paths[[\"trait_data\"]])[[\"trait.data\"]]\n                if (length(trait.data.check) != length(existing_trait_data)) {\n",
        "                  PEcAn.logger::logger.warn(\"Lengths of new and existing `trait.data` differ. \", \n                    \"Re-running meta-analysis.\")\n                  foundallfiles <- FALSE\n                }\n                else if (length(trait.data.check) == 0) {\n                  PEcAn.logger::logger.warn(\"New and existing trait data are both empty. Skipping this check.\")\n                }\n                else {\n                  current_traits <- dplyr::bind_rows(trait.data.check, \n                    .id = \"trait\") %>% dplyr::select(-mean, -stat)\n",
        "                  existing_traits <- dplyr::bind_rows(existing_trait_data, \n                    .id = \"trait\") %>% dplyr::select(-mean, -stat)\n                  diff_traits <- symmetric_setdiff(current_traits, \n                    existing_traits)\n                  if (nrow(diff_traits) > 0) {\n                    diff_summary <- diff_traits %>% dplyr::count(source, \n                      trait)\n                    PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                      \"Here are the number of differing trait records by trait:\\n\", \n",
        "                      PEcAn.logger::print2string(diff_summary), \n                      wrap = FALSE)\n                    foundallfiles <- FALSE\n                  }\n                }\n            }\n            if (foundallfiles) {\n                PEcAn.logger::logger.info(\"Reusing existing files from posterior\", \n                  pft$posteriorid, \"for PFT\", shQuote(pft$name))\n                for (id in seq_len(nrow(files))) {\n                  file.copy(from = file.path(files[[id, \"file_path\"]], \n                    files[[id, \"file_name\"]]), to = file.path(pft$outdir, \n",
        "                    files[[id, \"file_name\"]]))\n                }\n                done <- TRUE\n                if (length(list.files(pft$outdir, \"post.distns.Rdata\")) == \n                  0) {\n                  all.files <- list.files(pft$outdir)\n                  post.distn.file <- all.files[grep(\"post\\\\.distns\\\\..*\\\\.Rdata\", \n                    all.files)]\n                  if (length(post.distn.file) > 1) \n                    PEcAn.logger::logger.severe(\"get.trait.data.pft() doesn't know how to \", \n                      \"handle multiple `post.distns.*.Rdata` files.\", \n",
        "                      \"Found the following files: \", paste(shQuote(post.distn.file), \n                        collapse = \", \"))\n                  else if (length(post.distn.file) == 1) {\n                    link_input <- file.path(pft[[\"outdir\"]], \n                      post.distn.file)\n                    link_target <- file.path(pft[[\"outdir\"]], \n                      \"post.distns.Rdata\")\n                    PEcAn.logger::logger.debug(\"Found exactly one posterior distribution file: \", \n                      shQuote(link_input), \". Symlinking it to PFT output directory: \", \n",
        "                      shQuote(link_target))\n                    file.symlink(from = link_input, to = link_target)\n                  }\n                  else {\n                    PEcAn.logger::logger.error(\"No previous posterior distribution file found. \", \n                      \"Most likely, trait data were retrieved, but meta-analysis \", \n                      \"was not run. Meta-analysis will be run.\")\n                    done <- FALSE\n                  }\n                }\n                if (done) \n                  return(pft)\n",
        "            }\n        }\n    }\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (is.null(pft$posteriorid)) {\n    recent_posterior <- dplyr::tbl(dbcon, \"posteriors\") %>% dplyr::filter(pft_id == \n        !!pftid) %>% dplyr::collect()\n    if (length(recent_posterior) > 0) {\n        pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% \n            dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n            head(1) %>% dplyr::pull(id)\n    }\n    else {\n        PEcAn.logger::logger.info(\"No previous posterior found. Forcing update\")\n    }\n}\n",
        "Browse[2]> ",
        "dplyr::tbl(dbcon, \"posteriors\")",
        "[38;5;246m# Source:   table<posteriors> [?? x 4][39m\n[38;5;246m# Database: postgres 9.5.15 [bety@postgres:5432/bety][39m\n         id   pft_id created_at          updated_at         \n      [3m[38;5;246m<dbl>[39m[23m    [3m[38;5;246m<dbl>[39m[23m [3m[38;5;246m<dttm>[39m[23m              [3m[38;5;246m<dttm>[39m[23m             \n[38;5;250m 1[39m   2.00[38;5;246me[39m9   1.00[38;5;246me[39m9 2015-09-02 [38;5;246m16:44:48[39m 2015-09-02 [38;5;246m16:44:48[39m\n[38;5;250m 2[39m   2.00[38;5;246me[39m9   1.00[38;5;246me[39m9 2018-03-14 [38;5;246m08:09:48[39m 2018-03-14 [38;5;246m08:09:48[39m\n",
        "[38;5;250m 3[39m   2.00[38;5;246me[39m9   1.25[38;5;246me[39m2 2015-09-28 [38;5;246m10:53:28[39m 2015-09-28 [38;5;246m10:53:28[39m\n[38;5;250m 4[39m   2.00[38;5;246me[39m9   1.26[38;5;246me[39m2 2015-09-30 [38;5;246m17:44:35[39m 2015-09-30 [38;5;246m17:44:35[39m\n[38;5;250m 5[39m   2.00[38;5;246me[39m9   1.24[38;5;246me[39m2 2015-09-28 [38;5;246m14:55:21[39m 2015-09-28 [38;5;246m14:55:21[39m\n[38;5;250m 6[39m   2.00[38;5;246me[39m9   1.26[38;5;246me[39m2 2015-10-01 [38;5;246m13:47:12[39m 2015-10-01 [38;5;246m13:47:12[39m\n",
        "[38;5;250m 7[39m   2.00[38;5;246me[39m9   5.40[38;5;246me[39m1 2015-10-02 [38;5;246m11:50:06[39m 2015-10-02 [38;5;246m11:50:06[39m\n[38;5;250m 8[39m   2.00[38;5;246me[39m9   1.26[38;5;246me[39m2 2015-10-28 [38;5;246m15:23:36[39m 2015-10-28 [38;5;246m15:23:36[39m\n[38;5;250m 9[39m   2.00[38;5;246me[39m9   2.00[38;5;246me[39m9 2018-06-26 [38;5;246m15:03:21[39m 2018-06-26 [38;5;246m15:03:21[39m\n[38;5;250m10[39m   2.00[38;5;246me[39m9   7.90[38;5;246me[39m1 2015-10-22 [38;5;246m13:39:52[39m 2015-10-22 [38;5;246m13:39:52[39m\n",
        "[38;5;246m# … with more rows[39m\n",
        "Browse[2]> ",
        "dplyr::tbl(dbcon, \"posteriors\") %>% ",
        "+ ",
        "    dplyr::filter(pft_id == !!pftid)",
        "[38;5;246m# Source:   lazy query [?? x 4][39m\n[38;5;246m# Database: postgres 9.5.15 [bety@postgres:5432/bety][39m\n         id   pft_id created_at          updated_at         \n      [3m[38;5;246m<dbl>[39m[23m    [3m[38;5;246m<dbl>[39m[23m [3m[38;5;246m<dttm>[39m[23m              [3m[38;5;246m<dttm>[39m[23m             \n[38;5;250m 1[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m14:05:16[39m 2019-09-05 [38;5;246m14:05:16[39m\n[38;5;250m 2[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:53:13[39m 2019-09-03 [38;5;246m18:53:13[39m\n",
        "[38;5;250m 3[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m15:53:58[39m 2019-09-05 [38;5;246m15:53:58[39m\n[38;5;250m 4[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:09:56[39m 2019-09-05 [38;5;246m16:09:56[39m\n[38;5;250m 5[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:54:17[39m 2019-09-03 [38;5;246m18:54:17[39m\n[38;5;250m 6[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:03:44[39m 2019-09-03 [38;5;246m19:03:44[39m\n",
        "[38;5;250m 7[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:10:59[39m 2019-09-05 [38;5;246m16:10:59[39m\n[38;5;250m 8[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:04:21[39m 2019-09-03 [38;5;246m19:04:21[39m\n[38;5;250m 9[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:20:08[39m 2019-09-05 [38;5;246m16:20:08[39m\n[38;5;250m10[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:27:28[39m 2019-09-05 [38;5;246m16:27:28[39m\n",
        "[38;5;246m# … with more rows[39m\n",
        "Browse[2]> ",
        "dplyr::tbl(dbcon, \"posteriors\") %>% ",
        "+ ",
        "    dplyr::filter(pft_id == !!pftid) %>% dplyr::collect()",
        "[38;5;246m# A tibble: 33 x 4[39m\n         id   pft_id created_at          updated_at         \n      [3m[38;5;246m<dbl>[39m[23m    [3m[38;5;246m<dbl>[39m[23m [3m[38;5;246m<dttm>[39m[23m              [3m[38;5;246m<dttm>[39m[23m             \n[38;5;250m 1[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m14:05:16[39m 2019-09-05 [38;5;246m14:05:16[39m\n[38;5;250m 2[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:53:13[39m 2019-09-03 [38;5;246m18:53:13[39m\n",
        "[38;5;250m 3[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m15:53:58[39m 2019-09-05 [38;5;246m15:53:58[39m\n[38;5;250m 4[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:09:56[39m 2019-09-05 [38;5;246m16:09:56[39m\n[38;5;250m 5[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:54:17[39m 2019-09-03 [38;5;246m18:54:17[39m\n[38;5;250m 6[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:03:44[39m 2019-09-03 [38;5;246m19:03:44[39m\n",
        "[38;5;250m 7[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:10:59[39m 2019-09-05 [38;5;246m16:10:59[39m\n[38;5;250m 8[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:04:21[39m 2019-09-03 [38;5;246m19:04:21[39m\n[38;5;250m 9[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:20:08[39m 2019-09-05 [38;5;246m16:20:08[39m\n[38;5;250m10[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:27:28[39m 2019-09-05 [38;5;246m16:27:28[39m\n",
        "[38;5;246m# … with 23 more rows[39m\n",
        "Browse[2]> ",
        "Q",
        "\nRestarting R session...\n\n",
        "> ",
        "#!/usr/bin/env Rscript",
        "> ",
        "#-------------------------------------------------------------------------------",
        "> ",
        "# Copyright (c) 2012 University of Illinois, NCSA.",
        "> ",
        "# All rights reserved. This program and the accompanying materials",
        "> ",
        "# are made available under the terms of the ",
        "> ",
        "# University of Illinois/NCSA Open Source License",
        "> ",
        "# which accompanies this distribution, and is available at",
        "> ",
        "# http://opensource.ncsa.illinois.edu/license.html",
        "> ",
        "#-------------------------------------------------------------------------------",
        "> ",
        "",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# Load required libraries",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "library(PEcAn.all)",
        "Loading required package: PEcAn.DB\n",
        "Loading required package: PEcAn.settings\n",
        "Loading required package: PEcAn.MA\n",
        "Loading required package: XML\n",
        "Loading required package: lattice\n",
        "Loading required package: MASS\n",
        "Loading required package: PEcAn.utils\n",
        "\nAttaching package: ‘PEcAn.utils’\n\n",
        "The following object is masked from ‘package:utils’:\n\n    download.file\n\n",
        "Loading required package: PEcAn.logger\n",
        "\nAttaching package: ‘PEcAn.logger’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    logger.debug, logger.error, logger.getLevel,\n    logger.info, logger.setLevel,\n    logger.setOutputFile, logger.setQuitOnSevere,\n    logger.setWidth, logger.severe, logger.warn\n\n",
        "Loading required package: PEcAn.uncertainty\n",
        "Loading required package: PEcAn.priors\n",
        "Loading required package: ggplot2\n",
        "Loading required package: ggmap\n",
        "Google Maps API Terms of Service: http://developers.google.com/maps/terms.\n",
        "Please cite ggmap if you use it: see citation('ggmap') for details.\n",
        "Loading required package: gridExtra\n",
        "\nAttaching package: ‘PEcAn.uncertainty’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    get.ensemble.samples, read.ensemble.output,\n    write.ensemble.configs\n\n",
        "Loading required package: PEcAn.data.atmosphere\n",
        "Loading required package: PEcAn.data.land\n",
        "Loading required package: datapack\n",
        "Loading required package: dataone\n",
        "Loading required package: redland\n",
        "Loading required package: sirt\n",
        "- sirt 3.1-80 (2019-01-04 12:08:59)\n",
        "Loading required package: sf\n",
        "Linking to GEOS 3.5.1, GDAL 2.1.2, PROJ 4.9.3\n",
        "Loading required package: PEcAn.data.remote\n",
        "Loading required package: PEcAn.assim.batch\n",
        "Loading required package: PEcAn.emulator\n",
        "Loading required package: mvtnorm\n",
        "Loading required package: mlegp\n",
        "Loading required package: MCMCpack\n",
        "Loading required package: coda\n",
        "##\n## Markov Chain Monte Carlo Package (MCMCpack)\n",
        "## Copyright (C) 2003-2019 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park\n",
        "##\n## Support provided by the U.S. National Science Foundation\n",
        "## (Grants SES-0350646 and SES-0350613)\n##\n",
        "Loading required package: PEcAn.benchmark\n",
        "Loading required package: PEcAn.remote\n",
        "Loading required package: PEcAn.workflow\n",
        "\nAttaching package: ‘PEcAn.workflow’\n\n",
        "The following objects are masked from ‘package:PEcAn.utils’:\n\n    do_conversions, run.write.configs,\n    runModule.run.write.configs\n\n",
        "> ",
        "debugonce(PEcAn.DB::get.trait.data.pft)",
        "> ",
        "library(PEcAn.utils)",
        "> ",
        "library(RCurl)",
        "Loading required package: bitops\n",
        "> ",
        "",
        "> ",
        "# make sure always to call status.end",
        "> ",
        "options(warn=1)",
        "> ",
        "options(error=quote({",
        "+ ",
        "  PEcAn.utils::status.end(\"ERROR\")",
        "+ ",
        "  PEcAn.remote::kill.tunnel(settings)",
        "+ ",
        "  if (!interactive()) {",
        "+ ",
        "    q(status = 1)",
        "+ ",
        "  }",
        "+ ",
        "}))",
        "> ",
        "",
        "> ",
        "#options(warning.expression=status.end(\"ERROR\"))",
        "> ",
        "",
        "> ",
        "",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# PEcAn Workflow",
        "> ",
        "# ----------------------------------------------------------------------",
        "> ",
        "# Open and read in settings file for PEcAn run.",
        "> ",
        "args <- commandArgs(trailingOnly = TRUE)",
        "> ",
        "if (is.na(args[1])){",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(\"biocro_darpa_files/pecan.biocro.darpa.xml\") ",
        "+ ",
        "} else {",
        "+ ",
        "  settings.file <- args[1]",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(settings.file)",
        "+ ",
        "}",
        "2019-09-09 19:04:05 INFO   [#2: PEcAn.settings::read.settings] : \n   Loading inpufile= biocro_darpa_files/pecan.biocro.darpa.xml \n",
        "> ",
        "",
        "> ",
        "# Check for additional modules that will require adding settings",
        "> ",
        "if(\"benchmarking\" %in% names(settings)){",
        "+ ",
        "  library(PEcAn.benchmark)",
        "+ ",
        "  settings <- papply(settings, read_settings_BRR)",
        "+ ",
        "}",
        "> ",
        "",
        "> ",
        "if(\"sitegroup\" %in% names(settings)){",
        "+ ",
        "  if(is.null(settings$sitegroup$nSite)){",
        "+ ",
        "    settings <- PEcAn.settings::createSitegroupMultiSettings(settings, ",
        "+ ",
        "                                                             sitegroupId = settings$sitegroup$id)",
        "+ ",
        "  } else {",
        "+ ",
        "    settings <- PEcAn.settings::createSitegroupMultiSettings(settings, ",
        "+ ",
        "                                                             sitegroupId = settings$sitegroup$id,",
        "+ ",
        "                                                             nSite = settings$sitegroup$nSite)",
        "+ ",
        "  }",
        "+ ",
        "  settings$sitegroup <- NULL ## zero out so don't expand a second time if re-reading",
        "+ ",
        "}",
        "> ",
        "",
        "> ",
        "# Update/fix/check settings. Will only run the first time it's called, unless force=TRUE",
        "> ",
        "settings <- PEcAn.settings::prepare.settings(settings, force = FALSE)",
        "2019-09-09 19:04:05 INFO   [fix.deprecated.settings] : \n   Fixing deprecated settings... \n",
        "2019-09-09 19:04:05 INFO   [fix.deprecated.settings] : \n   settings$run$host is deprecated. uwe settings$host instead \n",
        "2019-09-09 19:04:05 INFO   [update.settings] : \n   Fixing deprecated settings... \n",
        "2019-09-09 19:04:05 INFO   [check.settings] : Checking settings... \n",
        "2019-09-09 19:04:05 INFO   [check.database] : \n   Successfully connected to database : PostgreSQL bety bety postgres bety \n   FALSE \n",
        "2019-09-09 19:04:05 WARN   [check.database.settings] : \n   Will not write runs/configurations to database. \n",
        "2019-09-09 19:04:05 WARN   [check.bety.version] : \n   Last migration 20181129000515 is more recent than expected \n   20141009160121. This could result in PEcAn not working as expected. \n",
        "2019-09-09 19:04:05 INFO   [check.ensemble.settings] : \n   Setting ensemble size to 1. \n",
        "2019-09-09 19:04:05 INFO   [check.ensemble.settings] : \n   No start date passed to ensemble - using the run date ( 2004 ). \n",
        "2019-09-09 19:04:05 INFO   [check.ensemble.settings] : \n   No end date passed to ensemble - using the run date ( 2004 ). \n",
        "2019-09-09 19:04:05 INFO   [check.ensemble.settings] : \n   We are updating the ensemble tag inside the xml file. \n",
        "2019-09-09 19:04:05 INFO   [fn] : \n   Setting site name to Donald Danforth Plant Science Center Growth Chamber \n   157 \n",
        "2019-09-09 19:04:05 INFO   [fn] : \n   Setting site lat to 38.674593 \n",
        "2019-09-09 19:04:05 INFO   [fn] : \n   Setting site lon to -90.397189 \n",
        "2019-09-09 19:04:05 WARN   [check.model.settings] : \n   Model type BIOCRO not in database \n",
        "2019-09-09 19:04:05 INFO   [check.model.settings] : \n   Setting model id to -1 \n",
        "2019-09-09 19:04:05 INFO   [check.model.settings] : \n   Option to delete raw model output not set or not logical. Will keep all \n   model output. \n",
        "2019-09-09 19:04:05 WARN   [check.model.settings] : \n   No model binary sepcified in database for model BIOCRO \n",
        "2019-09-09 19:04:05 WARN   [check.settings] : \n   settings$database$dbfiles pathname biocro_darpa_results/dbfiles is \n   invalid \n  \n   placing it in the home directory /home/kristinariemer \n",
        "2019-09-09 19:04:05 INFO   [fn] : \n   Missing optional input : soil \n",
        "2019-09-09 19:04:05 WARN   [PEcAn.DB::dbfile.id] : \n   no id found for \n   /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 in \n   database \n",
        "2019-09-09 19:04:05 INFO   [fn] : \n   path /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "2019-09-09 19:04:05 INFO   [fn] : \n   path /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "2019-09-09 19:04:05 INFO   [check.workflow.settings] : \n   output folder = /home/kristinariemer/biocro_darpa_results \n",
        "2019-09-09 19:04:05 INFO   [check.settings] : \n   Storing pft Setaria WT in \n   /home/kristinariemer/biocro_darpa_results/pft/Setaria WT \n",
        "> ",
        "",
        "> ",
        "# Write pecan.CHECKED.xml",
        "> ",
        "PEcAn.settings::write.settings(settings, outputfile = \"pecan.CHECKED.xml\")",
        "2019-09-09 19:04:05 WARN   [PEcAn.settings::write.settings] : \n   File already exists [ \n   /home/kristinariemer/biocro_darpa_results/pecan.CHECKED.xml ] file will \n   be overwritten \n",
        "[1] \"/home/kristinariemer/biocro_darpa_results/pecan.CHECKED.xml\"\n",
        "> ",
        "",
        "> ",
        "# start from scratch if no continue is passed in",
        "> ",
        "statusFile <- file.path(settings$outdir, \"STATUS\")",
        "> ",
        "if (length(which(commandArgs() == \"--continue\")) == 0 && file.exists(statusFile)) {",
        "+ ",
        "  file.remove(statusFile)",
        "+ ",
        "}",
        "[1] TRUE\n",
        "> ",
        "",
        "> ",
        "# Do conversions",
        "> ",
        "settings <- PEcAn.workflow::do_conversions(settings)",
        "2019-09-09 19:04:06 DEBUG  [PEcAn.workflow::do_conversions] : \n   do.conversion outdir /home/kristinariemer/biocro_darpa_results/dbfiles \n",
        "2019-09-09 19:04:06 INFO   [PEcAn.workflow::do_conversions] : PROCESSING:  met \n",
        "2019-09-09 19:04:06 INFO   [PEcAn.workflow::do_conversions] : \n   calling met.process: \n   /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "2019-09-09 19:04:06 WARN   [PEcAn.data.atmosphere::met.process] : \n   met.process only has a path provided, assuming path is model driver and \n   skipping processing \n",
        "2019-09-09 19:04:06 DEBUG  [PEcAn.workflow::do_conversions] : \n   updated met path: \n   /home/kristinariemer/pecan/models/biocro/tests/testthat/data/US-Bo1 \n",
        "> ",
        "",
        "> ",
        "# Query the trait database for data and priors",
        "> ",
        "if (PEcAn.utils::status.check(\"TRAIT\") == 0){",
        "+ ",
        "  PEcAn.utils::status.start(\"TRAIT\")",
        "+ ",
        "  settings <- PEcAn.workflow::runModule.get.trait.data(settings)",
        "+ ",
        "  PEcAn.settings::write.settings(settings, outputfile='pecan.TRAIT.xml')",
        "+ ",
        "  PEcAn.utils::status.end()",
        "+ ",
        "} else if (file.exists(file.path(settings$outdir, 'pecan.TRAIT.xml'))) {",
        "+ ",
        "  settings <- PEcAn.settings::read.settings(file.path(settings$outdir, 'pecan.TRAIT.xml'))",
        "+ ",
        "}",
        "2019-09-09 19:04:06 DEBUG  [PEcAn.DB::get.trait.data] : \n   `trait.names` is NULL, so retrieving all traits that have at least one \n   prior for these PFTs. \n",
        "debugging in: FUN(X[[i]], ...)\ndebug: {\n    if (!file.exists(pft$outdir) && !dir.create(pft$outdir, recursive = TRUE)) {\n        PEcAn.logger::logger.error(paste0(\"Couldn't create PFT output directory: \", \n            pft$outdir))\n    }\n    old.files <- list.files(path = pft$outdir, full.names = TRUE, \n        include.dirs = FALSE)\n    file.remove(old.files)\n    pftres <- query_pfts(dbcon, pft[[\"name\"]], modeltype)\n    pfttype <- pftres[[\"pft_type\"]]\n    pftid <- pftres[[\"id\"]]\n    if (nrow(pftres) > 1) {\n        PEcAn.logger::logger.severe(\"Multiple PFTs named\", pft[[\"name\"]], \n",
        "            \"found,\", \"with ids\", PEcAn.utils::vecpaste(pftres[[\"id\"]]), \n            \".\", \"Specify modeltype to fix this.\")\n    }\n    if (nrow(pftres) == 0) {\n        PEcAn.logger::logger.severe(\"Could not find pft\", pft[[\"name\"]])\n        return(NA)\n    }\n    if (pfttype == \"plant\") {\n        pft_member_filename = \"species.csv\"\n        pft_members <- PEcAn.DB::query.pft_species(pft$name, \n            modeltype, dbcon)\n    }\n    else if (pfttype == \"cultivar\") {\n        pft_member_filename = \"cultivars.csv\"\n",
        "        pft_members <- PEcAn.DB::query.pft_cultivars(pft$name, \n            modeltype, dbcon)\n    }\n    else {\n        PEcAn.logger::logger.severe(\"Unknown pft type! Expected 'plant' or 'cultivar', got\", \n            pfttype)\n    }\n    pft_members <- pft_members %>% dplyr::mutate_if(is.character, \n        ~dplyr::na_if(., \"\"))\n    prior.distns <- PEcAn.DB::query.priors(pft = pftid, trstr = PEcAn.utils::vecpaste(trait.names), \n        con = dbcon)\n    prior.distns <- prior.distns[which(!rownames(prior.distns) %in% \n",
        "        names(pft$constants)), ]\n    traits <- rownames(prior.distns)\n    trait.data.check <- PEcAn.DB::query.traits(ids = pft_members$id, \n        priors = traits, con = dbcon, update.check.only = TRUE, \n        ids_are_cultivars = (pfttype == \"cultivar\"))\n    traits <- names(trait.data.check)\n    if (!is.logical(forceupdate)) {\n        forceupdate <- FALSE\n    }\n    if (!forceupdate) {\n        if (is.null(pft$posteriorid)) {\n            recent_posterior <- dplyr::tbl(dbcon, \"posteriors\") %>% \n                dplyr::filter(pft_id == !!pftid) %>% dplyr::collect()\n",
        "            if (length(recent_posterior) > 0) {\n                pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% \n                  dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n                  head(1) %>% dplyr::pull(id)\n            }\n            else {\n                PEcAn.logger::logger.info(\"No previous posterior found. Forcing update\")\n            }\n        }\n        if (!is.null(pft$posteriorid)) {\n            files <- dbfile.check(type = \"Posterior\", container.id = pft$posteriorid, \n",
        "                con = dbcon, return.all = TRUE)\n            need_files <- c(trait_data = \"trait.data.Rdata\", \n                priors = \"prior.distns.Rdata\", pft_membership = pft_member_filename)\n            ids <- match(need_files, files$file_name)\n            names(ids) <- names(need_files)\n            if (any(is.na(ids))) {\n                missing_files <- need_files[is.na(ids)]\n                PEcAn.logger::logger.info(paste0(\"Forcing meta-analysis update because \", \n                  \"the following files are missing from the posterior: \", \n",
        "                  paste0(shQuote(missing_files), collapse = \", \")))\n                PEcAn.logger::logger.debug(\"\\n `dbfile.check` returned the following output:\\n\", \n                  PEcAn.logger::print2string(files), wrap = FALSE)\n            }\n            else {\n                PEcAn.logger::logger.debug(\"All posterior files are present. Performing additional checks \", \n                  \"to determine if meta-analysis needs to be updated.\")\n                need_paths <- file.path(files$file_path[ids], \n                  need_files)\n",
        "                names(need_paths) <- names(need_files)\n                files_exist <- file.exists(need_paths)\n                foundallfiles <- all(files_exist)\n                if (!foundallfiles) {\n                  PEcAn.logger::logger.warn(\"The following files are in database but not found on disk: \", \n                    paste(shQuote(need_files[!files_exist]), \n                      collapse = \", \"), \". \", \"Re-running meta-analysis.\")\n                }\n                else {\n                  PEcAn.logger::logger.debug(\"Checking if PFT membership has changed.\")\n",
        "                  existing_membership <- utils::read.csv(need_paths[[\"pft_membership\"]], \n                    colClasses = c(\"double\", \"character\", \"character\", \n                      \"character\"), stringsAsFactors = FALSE, \n                    na.strings = \"\")\n                  diff_membership <- symmetric_setdiff(existing_membership, \n                    pft_members, xname = \"existing\", yname = \"current\")\n                  if (nrow(diff_membership) > 0) {\n                    PEcAn.logger::logger.error(\"\\n PFT membership has changed. \\n\", \n",
        "                      \"Difference is:\\n\", PEcAn.logger::print2string(diff_membership), \n                      wrap = FALSE)\n                    foundallfiles <- FALSE\n                  }\n                  PEcAn.logger::logger.debug(\"Checking if priors have changed\")\n                  existing_prior <- PEcAn.utils::load_local(need_paths[[\"priors\"]])[[\"prior.distns\"]]\n                  diff_prior <- symmetric_setdiff(dplyr::as_tibble(prior.distns, \n                    rownames = \"trait\"), dplyr::as_tibble(existing_prior, \n",
        "                    rownames = \"trait\"))\n                  if (nrow(diff_prior) > 0) {\n                    PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                      \"Difference is:\\n\", PEcAn.logger::print2string(diff_prior), \n                      wrap = FALSE)\n                    foundallfiles <- FALSE\n                  }\n                  PEcAn.logger::logger.debug(\"Checking if trait data have changed\")\n                  existing_trait_data <- PEcAn.utils::load_local(need_paths[[\"trait_data\"]])[[\"trait.data\"]]\n",
        "                  if (length(trait.data.check) != length(existing_trait_data)) {\n                    PEcAn.logger::logger.warn(\"Lengths of new and existing `trait.data` differ. \", \n                      \"Re-running meta-analysis.\")\n                    foundallfiles <- FALSE\n                  }\n                  else if (length(trait.data.check) == 0) {\n                    PEcAn.logger::logger.warn(\"New and existing trait data are both empty. Skipping this check.\")\n                  }\n                  else {\n",
        "                    current_traits <- dplyr::bind_rows(trait.data.check, \n                      .id = \"trait\") %>% dplyr::select(-mean, \n                      -stat)\n                    existing_traits <- dplyr::bind_rows(existing_trait_data, \n                      .id = \"trait\") %>% dplyr::select(-mean, \n                      -stat)\n                    diff_traits <- symmetric_setdiff(current_traits, \n                      existing_traits)\n                    if (nrow(diff_traits) > 0) {\n                      diff_summary <- diff_traits %>% dplyr::count(source, \n",
        "                        trait)\n                      PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                        \"Here are the number of differing trait records by trait:\\n\", \n                        PEcAn.logger::print2string(diff_summary), \n                        wrap = FALSE)\n                      foundallfiles <- FALSE\n                    }\n                  }\n                }\n                if (foundallfiles) {\n                  PEcAn.logger::logger.info(\"Reusing existing files from posterior\", \n",
        "                    pft$posteriorid, \"for PFT\", shQuote(pft$name))\n                  for (id in seq_len(nrow(files))) {\n                    file.copy(from = file.path(files[[id, \"file_path\"]], \n                      files[[id, \"file_name\"]]), to = file.path(pft$outdir, \n                      files[[id, \"file_name\"]]))\n                  }\n                  done <- TRUE\n                  if (length(list.files(pft$outdir, \"post.distns.Rdata\")) == \n                    0) {\n                    all.files <- list.files(pft$outdir)\n",
        "                    post.distn.file <- all.files[grep(\"post\\\\.distns\\\\..*\\\\.Rdata\", \n                      all.files)]\n                    if (length(post.distn.file) > 1) \n                      PEcAn.logger::logger.severe(\"get.trait.data.pft() doesn't know how to \", \n                        \"handle multiple `post.distns.*.Rdata` files.\", \n                        \"Found the following files: \", paste(shQuote(post.distn.file), \n                          collapse = \", \"))\n                    else if (length(post.distn.file) == 1) {\n",
        "                      link_input <- file.path(pft[[\"outdir\"]], \n                        post.distn.file)\n                      link_target <- file.path(pft[[\"outdir\"]], \n                        \"post.distns.Rdata\")\n                      PEcAn.logger::logger.debug(\"Found exactly one posterior distribution file: \", \n                        shQuote(link_input), \". Symlinking it to PFT output directory: \", \n                        shQuote(link_target))\n                      file.symlink(from = link_input, to = link_target)\n",
        "                    }\n                    else {\n                      PEcAn.logger::logger.error(\"No previous posterior distribution file found. \", \n                        \"Most likely, trait data were retrieved, but meta-analysis \", \n                        \"was not run. Meta-analysis will be run.\")\n                      done <- FALSE\n                    }\n                  }\n                  if (done) \n                    return(pft)\n                }\n            }\n        }\n    }\n    trait.data <- query.traits(pft_members$id, traits, con = dbcon, \n",
        "        update.check.only = FALSE, ids_are_cultivars = (pfttype == \n            \"cultivar\"))\n    traits <- names(trait.data)\n    if (length(trait.data) > 0) {\n        trait_counts <- trait.data %>% dplyr::bind_rows(.id = \"trait\") %>% \n            dplyr::count(trait)\n        PEcAn.logger::logger.info(\"\\n Number of observations per trait for PFT \", \n            shQuote(pft[[\"name\"]]), \":\\n\", PEcAn.logger::print2string(trait_counts, \n                n = Inf), wrap = FALSE)\n    }\n    else {\n        PEcAn.logger::logger.warn(\"None of the requested traits were found for PFT \", \n",
        "            format(pft_members[[\"id\"]], scientific = FALSE))\n    }\n    old.files <- list.files(path = pft$outdir)\n    now <- format(x = Sys.time(), format = \"%Y-%m-%d %H:%M:%S\")\n    db.query(paste0(\"INSERT INTO posteriors (pft_id, created_at, updated_at) \", \n        \"VALUES (\", pftid, \", '\", now, \"', '\", now, \"')\"), con = dbcon)\n    pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% dplyr::filter(pft_id == \n        !!pftid, created_at == !!now) %>% dplyr::pull(id)\n    pathname <- file.path(dbfiles, \"posterior\", pft$posteriorid)\n",
        "    dir.create(pathname, showWarnings = FALSE, recursive = TRUE)\n    utils::write.csv(pft_members, file.path(pft$outdir, pft_member_filename), \n        row.names = FALSE)\n    save(prior.distns, file = file.path(pft$outdir, \"prior.distns.Rdata\"))\n    utils::write.csv(prior.distns, file.path(pft$outdir, \"prior.distns.csv\"), \n        row.names = TRUE)\n    PEcAn.logger::logger.info(\"\\n Summary of prior distributions for PFT \", \n        shQuote(pft$name), \":\\n\", PEcAn.logger::print2string(prior.distns), \n        wrap = FALSE)\n",
        "    trait.data.file <- file.path(pft$outdir, \"trait.data.Rdata\")\n    save(trait.data, file = trait.data.file)\n    utils::write.csv(dplyr::bind_rows(trait.data), file.path(pft$outdir, \n        \"trait.data.csv\"), row.names = FALSE)\n    store_files_all <- list.files(path = pft[[\"outdir\"]])\n    store_files <- setdiff(store_files_all, old.files)\n    PEcAn.logger::logger.debug(\"The following posterior files found in PFT outdir \", \n        \"(\", shQuote(pft[[\"outdir\"]]), \") will be registered in BETY \", \n        \"under posterior ID \", format(pft[[\"posteriorid\"]], scientific = FALSE), \n",
        "        \": \", paste(shQuote(store_files), collapse = \", \"), \". \", \n        \"The following files (if any) will not be registered because they already existed: \", \n        paste(shQuote(intersect(store_files, old.files)), collapse = \", \"), \n        wrap = FALSE)\n    for (file in store_files) {\n        filename <- file.path(pathname, file)\n        file.copy(file.path(pft$outdir, file), filename)\n        dbfile.insert(in.path = pathname, in.prefix = file, type = \"Posterior\", \n            id = pft[[\"posteriorid\"]], con = dbcon)\n",
        "    }\n    return(pft)\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (!file.exists(pft$outdir) && !dir.create(pft$outdir, recursive = TRUE)) {\n    PEcAn.logger::logger.error(paste0(\"Couldn't create PFT output directory: \", \n        pft$outdir))\n}\n",
        "Browse[2]> ",
        "",
        "debug: old.files <- list.files(path = pft$outdir, full.names = TRUE, \n    include.dirs = FALSE)\n",
        "Browse[2]> ",
        "",
        "debug: file.remove(old.files)\n",
        "Browse[2]> ",
        "",
        "debug: pftres <- query_pfts(dbcon, pft[[\"name\"]], modeltype)\n",
        "Browse[2]> ",
        "",
        "debug: pfttype <- pftres[[\"pft_type\"]]\n",
        "Browse[2]> ",
        "",
        "debug: pftid <- pftres[[\"id\"]]\n",
        "Browse[2]> ",
        "",
        "debug: if (nrow(pftres) > 1) {\n    PEcAn.logger::logger.severe(\"Multiple PFTs named\", pft[[\"name\"]], \n        \"found,\", \"with ids\", PEcAn.utils::vecpaste(pftres[[\"id\"]]), \n        \".\", \"Specify modeltype to fix this.\")\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (nrow(pftres) == 0) {\n    PEcAn.logger::logger.severe(\"Could not find pft\", pft[[\"name\"]])\n    return(NA)\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (pfttype == \"plant\") {\n    pft_member_filename = \"species.csv\"\n    pft_members <- PEcAn.DB::query.pft_species(pft$name, modeltype, \n        dbcon)\n} else if (pfttype == \"cultivar\") {\n    pft_member_filename = \"cultivars.csv\"\n    pft_members <- PEcAn.DB::query.pft_cultivars(pft$name, modeltype, \n        dbcon)\n} else {\n    PEcAn.logger::logger.severe(\"Unknown pft type! Expected 'plant' or 'cultivar', got\", \n        pfttype)\n}\n",
        "Browse[2]> ",
        "",
        "debug: pft_member_filename = \"species.csv\"\n",
        "Browse[2]> ",
        "",
        "debug: pft_members <- PEcAn.DB::query.pft_species(pft$name, modeltype, \n    dbcon)\n",
        "Browse[2]> ",
        "",
        "debug: pft_members <- pft_members %>% dplyr::mutate_if(is.character, \n    ~dplyr::na_if(., \"\"))\n",
        "Browse[2]> ",
        "",
        "debug: prior.distns <- PEcAn.DB::query.priors(pft = pftid, trstr = PEcAn.utils::vecpaste(trait.names), \n    con = dbcon)\n",
        "Browse[2]> ",
        "",
        "debug: prior.distns <- prior.distns[which(!rownames(prior.distns) %in% \n    names(pft$constants)), ]\n",
        "Browse[2]> ",
        "",
        "debug: traits <- rownames(prior.distns)\n",
        "Browse[2]> ",
        "",
        "debug: trait.data.check <- PEcAn.DB::query.traits(ids = pft_members$id, \n    priors = traits, con = dbcon, update.check.only = TRUE, ids_are_cultivars = (pfttype == \n        \"cultivar\"))\n",
        "Browse[2]> ",
        "",
        "debug: traits <- names(trait.data.check)\n",
        "Browse[2]> ",
        "",
        "debug: if (!is.logical(forceupdate)) {\n    forceupdate <- FALSE\n}\n",
        "Browse[2]> ",
        "",
        "debug: forceupdate <- FALSE\n",
        "Browse[2]> ",
        "",
        "debug: if (!forceupdate) {\n    if (is.null(pft$posteriorid)) {\n        recent_posterior <- dplyr::tbl(dbcon, \"posteriors\") %>% \n            dplyr::filter(pft_id == !!pftid) %>% dplyr::collect()\n        if (length(recent_posterior) > 0) {\n            pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% \n                dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n                head(1) %>% dplyr::pull(id)\n        }\n        else {\n            PEcAn.logger::logger.info(\"No previous posterior found. Forcing update\")\n",
        "        }\n    }\n    if (!is.null(pft$posteriorid)) {\n        files <- dbfile.check(type = \"Posterior\", container.id = pft$posteriorid, \n            con = dbcon, return.all = TRUE)\n        need_files <- c(trait_data = \"trait.data.Rdata\", priors = \"prior.distns.Rdata\", \n            pft_membership = pft_member_filename)\n        ids <- match(need_files, files$file_name)\n        names(ids) <- names(need_files)\n        if (any(is.na(ids))) {\n            missing_files <- need_files[is.na(ids)]\n            PEcAn.logger::logger.info(paste0(\"Forcing meta-analysis update because \", \n",
        "                \"the following files are missing from the posterior: \", \n                paste0(shQuote(missing_files), collapse = \", \")))\n            PEcAn.logger::logger.debug(\"\\n `dbfile.check` returned the following output:\\n\", \n                PEcAn.logger::print2string(files), wrap = FALSE)\n        }\n        else {\n            PEcAn.logger::logger.debug(\"All posterior files are present. Performing additional checks \", \n                \"to determine if meta-analysis needs to be updated.\")\n            need_paths <- file.path(files$file_path[ids], need_files)\n",
        "            names(need_paths) <- names(need_files)\n            files_exist <- file.exists(need_paths)\n            foundallfiles <- all(files_exist)\n            if (!foundallfiles) {\n                PEcAn.logger::logger.warn(\"The following files are in database but not found on disk: \", \n                  paste(shQuote(need_files[!files_exist]), collapse = \", \"), \n                  \". \", \"Re-running meta-analysis.\")\n            }\n            else {\n                PEcAn.logger::logger.debug(\"Checking if PFT membership has changed.\")\n",
        "                existing_membership <- utils::read.csv(need_paths[[\"pft_membership\"]], \n                  colClasses = c(\"double\", \"character\", \"character\", \n                    \"character\"), stringsAsFactors = FALSE, na.strings = \"\")\n                diff_membership <- symmetric_setdiff(existing_membership, \n                  pft_members, xname = \"existing\", yname = \"current\")\n                if (nrow(diff_membership) > 0) {\n                  PEcAn.logger::logger.error(\"\\n PFT membership has changed. \\n\", \n",
        "                    \"Difference is:\\n\", PEcAn.logger::print2string(diff_membership), \n                    wrap = FALSE)\n                  foundallfiles <- FALSE\n                }\n                PEcAn.logger::logger.debug(\"Checking if priors have changed\")\n                existing_prior <- PEcAn.utils::load_local(need_paths[[\"priors\"]])[[\"prior.distns\"]]\n                diff_prior <- symmetric_setdiff(dplyr::as_tibble(prior.distns, \n                  rownames = \"trait\"), dplyr::as_tibble(existing_prior, \n                  rownames = \"trait\"))\n",
        "                if (nrow(diff_prior) > 0) {\n                  PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                    \"Difference is:\\n\", PEcAn.logger::print2string(diff_prior), \n                    wrap = FALSE)\n                  foundallfiles <- FALSE\n                }\n                PEcAn.logger::logger.debug(\"Checking if trait data have changed\")\n                existing_trait_data <- PEcAn.utils::load_local(need_paths[[\"trait_data\"]])[[\"trait.data\"]]\n                if (length(trait.data.check) != length(existing_trait_data)) {\n",
        "                  PEcAn.logger::logger.warn(\"Lengths of new and existing `trait.data` differ. \", \n                    \"Re-running meta-analysis.\")\n                  foundallfiles <- FALSE\n                }\n                else if (length(trait.data.check) == 0) {\n                  PEcAn.logger::logger.warn(\"New and existing trait data are both empty. Skipping this check.\")\n                }\n                else {\n                  current_traits <- dplyr::bind_rows(trait.data.check, \n                    .id = \"trait\") %>% dplyr::select(-mean, -stat)\n",
        "                  existing_traits <- dplyr::bind_rows(existing_trait_data, \n                    .id = \"trait\") %>% dplyr::select(-mean, -stat)\n                  diff_traits <- symmetric_setdiff(current_traits, \n                    existing_traits)\n                  if (nrow(diff_traits) > 0) {\n                    diff_summary <- diff_traits %>% dplyr::count(source, \n                      trait)\n                    PEcAn.logger::logger.error(\"\\n Prior has changed. \\n\", \n                      \"Here are the number of differing trait records by trait:\\n\", \n",
        "                      PEcAn.logger::print2string(diff_summary), \n                      wrap = FALSE)\n                    foundallfiles <- FALSE\n                  }\n                }\n            }\n            if (foundallfiles) {\n                PEcAn.logger::logger.info(\"Reusing existing files from posterior\", \n                  pft$posteriorid, \"for PFT\", shQuote(pft$name))\n                for (id in seq_len(nrow(files))) {\n                  file.copy(from = file.path(files[[id, \"file_path\"]], \n                    files[[id, \"file_name\"]]), to = file.path(pft$outdir, \n",
        "                    files[[id, \"file_name\"]]))\n                }\n                done <- TRUE\n                if (length(list.files(pft$outdir, \"post.distns.Rdata\")) == \n                  0) {\n                  all.files <- list.files(pft$outdir)\n                  post.distn.file <- all.files[grep(\"post\\\\.distns\\\\..*\\\\.Rdata\", \n                    all.files)]\n                  if (length(post.distn.file) > 1) \n                    PEcAn.logger::logger.severe(\"get.trait.data.pft() doesn't know how to \", \n                      \"handle multiple `post.distns.*.Rdata` files.\", \n",
        "                      \"Found the following files: \", paste(shQuote(post.distn.file), \n                        collapse = \", \"))\n                  else if (length(post.distn.file) == 1) {\n                    link_input <- file.path(pft[[\"outdir\"]], \n                      post.distn.file)\n                    link_target <- file.path(pft[[\"outdir\"]], \n                      \"post.distns.Rdata\")\n                    PEcAn.logger::logger.debug(\"Found exactly one posterior distribution file: \", \n                      shQuote(link_input), \". Symlinking it to PFT output directory: \", \n",
        "                      shQuote(link_target))\n                    file.symlink(from = link_input, to = link_target)\n                  }\n                  else {\n                    PEcAn.logger::logger.error(\"No previous posterior distribution file found. \", \n                      \"Most likely, trait data were retrieved, but meta-analysis \", \n                      \"was not run. Meta-analysis will be run.\")\n                    done <- FALSE\n                  }\n                }\n                if (done) \n                  return(pft)\n",
        "            }\n        }\n    }\n}\n",
        "Browse[2]> ",
        "",
        "debug: if (is.null(pft$posteriorid)) {\n    recent_posterior <- dplyr::tbl(dbcon, \"posteriors\") %>% dplyr::filter(pft_id == \n        !!pftid) %>% dplyr::collect()\n    if (length(recent_posterior) > 0) {\n        pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% \n            dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n            head(1) %>% dplyr::pull(id)\n    }\n    else {\n        PEcAn.logger::logger.info(\"No previous posterior found. Forcing update\")\n    }\n}\n",
        "Browse[2]> ",
        "",
        "debug: recent_posterior <- dplyr::tbl(dbcon, \"posteriors\") %>% dplyr::filter(pft_id == \n    !!pftid) %>% dplyr::collect()\n",
        "Browse[2]> ",
        "recent_posterior",
        "Error: object 'recent_posterior' not found\n",
        "Browse[2]> ",
        "",
        "debug: if (length(recent_posterior) > 0) {\n    pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% dplyr::filter(pft_id == \n        !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n        head(1) %>% dplyr::pull(id)\n} else {\n    PEcAn.logger::logger.info(\"No previous posterior found. Forcing update\")\n}\n",
        "Browse[2]> ",
        "recent_posterior",
        "[38;5;246m# A tibble: 33 x 4[39m\n         id   pft_id created_at          updated_at         \n      [3m[38;5;246m<dbl>[39m[23m    [3m[38;5;246m<dbl>[39m[23m [3m[38;5;246m<dttm>[39m[23m              [3m[38;5;246m<dttm>[39m[23m             \n[38;5;250m 1[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m14:05:16[39m 2019-09-05 [38;5;246m14:05:16[39m\n[38;5;250m 2[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:53:13[39m 2019-09-03 [38;5;246m18:53:13[39m\n",
        "[38;5;250m 3[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m15:53:58[39m 2019-09-05 [38;5;246m15:53:58[39m\n[38;5;250m 4[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:09:56[39m 2019-09-05 [38;5;246m16:09:56[39m\n[38;5;250m 5[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:54:17[39m 2019-09-03 [38;5;246m18:54:17[39m\n[38;5;250m 6[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:03:44[39m 2019-09-03 [38;5;246m19:03:44[39m\n",
        "[38;5;250m 7[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:10:59[39m 2019-09-05 [38;5;246m16:10:59[39m\n[38;5;250m 8[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:04:21[39m 2019-09-03 [38;5;246m19:04:21[39m\n[38;5;250m 9[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:20:08[39m 2019-09-05 [38;5;246m16:20:08[39m\n[38;5;250m10[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:27:28[39m 2019-09-05 [38;5;246m16:27:28[39m\n",
        "[38;5;246m# … with 23 more rows[39m\n",
        "Browse[2]> ",
        "pft$posteriorid",
        "NULL\n",
        "Browse[2]> ",
        "if (length(recent_posterior) > 0) {",
        "+ ",
        "    pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% ",
        "+ ",
        "        dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% ",
        "+ ",
        "        head(1) %>% dplyr::pull(id)",
        "+ ",
        "}",
        "debug at #2: pft$posteriorid <- dplyr::tbl(dbcon, \"posteriors\") %>% dplyr::filter(pft_id == \n    !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% \n    head(1) %>% dplyr::pull(id)\n",
        "Browse[3]> ",
        "pft$posteriorid",
        "NULL\n",
        "Browse[3]> ",
        "length(recent_posterior)",
        "[1] 4\n",
        "Browse[3]> ",
        "recent_posterior",
        "[38;5;246m# A tibble: 33 x 4[39m\n         id   pft_id created_at          updated_at         \n      [3m[38;5;246m<dbl>[39m[23m    [3m[38;5;246m<dbl>[39m[23m [3m[38;5;246m<dttm>[39m[23m              [3m[38;5;246m<dttm>[39m[23m             \n[38;5;250m 1[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m14:05:16[39m 2019-09-05 [38;5;246m14:05:16[39m\n[38;5;250m 2[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:53:13[39m 2019-09-03 [38;5;246m18:53:13[39m\n",
        "[38;5;250m 3[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m15:53:58[39m 2019-09-05 [38;5;246m15:53:58[39m\n[38;5;250m 4[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:09:56[39m 2019-09-05 [38;5;246m16:09:56[39m\n[38;5;250m 5[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m18:54:17[39m 2019-09-03 [38;5;246m18:54:17[39m\n[38;5;250m 6[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:03:44[39m 2019-09-03 [38;5;246m19:03:44[39m\n",
        "[38;5;250m 7[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:10:59[39m 2019-09-05 [38;5;246m16:10:59[39m\n[38;5;250m 8[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-03 [38;5;246m19:04:21[39m 2019-09-03 [38;5;246m19:04:21[39m\n[38;5;250m 9[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:20:08[39m 2019-09-05 [38;5;246m16:20:08[39m\n[38;5;250m10[39m   9.00[38;5;246me[39m9   9.00[38;5;246me[39m9 2019-09-05 [38;5;246m16:27:28[39m 2019-09-05 [38;5;246m16:27:28[39m\n",
        "[38;5;246m# … with 23 more rows[39m\n",
        "Browse[3]> ",
        "dplyr::tbl(dbcon, \"posteriors\") %>% ",
        "+ ",
        "    dplyr::filter(pft_id == !!pftid) %>% dplyr::arrange(dplyr::desc(created_at)) %>% ",
        "+ ",
        "    head(1) %>% dplyr::pull(id)",
        "[1] 9e+09\n",
        "Browse[3]> ",
        "Q"
    ],
    "type" : [
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        2,
        2,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        3,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        3,
        3,
        3,
        3,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        3,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        3,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        0,
        1,
        2,
        2,
        2,
        2,
        0,
        1,
        0,
        1,
        0,
        1,
        2,
        0,
        1
    ]
}